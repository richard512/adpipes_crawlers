###Порядок работы над краулером:

* перед тем как отметить на себя рекламную сеть в AdPipes, надо сделать поиск URL рек-ой сети в AdPipes на закладке
  Ad networks logins, и  в исходниках краулеров, возможно что разные рекл-ые сети используют один сервер,
  и краулер для него уже сделан.
* создавать новый краулер нужно в отдельной ветке с названием  “feature/{name}”
* после чего надо  создать merge request ветки “feature/{name}” в develop,
  и назначить другому разработчику для code review (Мураду).
* мелкие изменения, для которых сode review не имеет смысла,  можно комитить сразу в develop, без merge request,
  либо назначить  merge request самому себе.
* регулярно обновлять ветку develop
* если работаете в другой ветке ( не develop), то поддерживать актуальное состояние кода, делая  git merge develop.
* после того как краулер завершен, отметить в Adpipes на закладке Crawler status, и в Asana.


###Требования к краулерам:

* скрипт должен быть универсальным для любого аккаунта соответствующей рекламной сети.
* если в рекламной сети  вместо нулей бывают сообщения вроде No data, No results, в периодах в которых нет данных,
  то краулер должен возвращать нули. (могут быть исключения, когда лучше бросить Error c поясняющим сообщением).
* если что - то недоработано в коде, или есть особенности, например можно получить  данные только за 1 день,
  то это должно быть как-то зафиксировано. Например в коментарии #todo: data only for 1 day, или создать Issue в багтрекере,
  или отметить в коменте в AdPipes на закладке Crawler status.
* скрипт не должен давать неправильных результатов, если вернуть правильные результаты невозможно,
  то нужно бросить throw Error(“инфомативное сообщение”)
* другие требования в crawlers.md в папке docs.